{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "We start by importing \"Yet Another Keyword Extractor (Yake)\" - an open source unsupervised automatic Keyword extraction program."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "source": [
    "Next, we read in an input file with a large quantity of text to be analysed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data.txt\"\n",
    "\n",
    "f = open(filename, mode='r')\n",
    "text = f.read()"
   ]
  },
  {
   "source": [
    "Our first step of analysis is to summarise the text using the open source summary engine, SMMRY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In participants who received two standard doses, vaccine efficacy was 62·1% and in participants who received a low dose followed by a standard dose, efficacy was 90·0%. Overall vaccine efficacy across both groups was 70·4%. From 21 days after the first dose, there were ten cases hospitalised for COVID-19, all in the control arm; two were classified as severe COVID-19, including one death. Phase 2 cohort in COV002 in older adults6 have been published and show an acceptable safety profile for the vaccine with induction of binding and neutralising antibodies as well as generation of interferon-γ enzymelinked immunospot responses, with higher antibody titres after a second dose of vaccine. Two dosage groups were included in COV002: participants who received a low dose of the vaccine as their first dose and were boosted with a standard dose, and subse­ quent cohorts who were vaccinated with two standard-dose vaccines. The trial staff administering the vaccine pre­ pared vaccines out of sight of the par­ticipants and syringes were covered with an opaque material until ready for administration to ensure masking of participants. Were 30 cases among 5807 participants in the vaccine arm and 101 cases among 5829 par­ ticipants in the control group, resulting in vaccine efficacy of 70·4%. In participants who received two standard-dose vaccines, vaccine efficacy was 62·1%, whereas in those who received a low dose as their first dose of vaccine, efficacy was higher at 90·0%. In England and Wales, 129 529 weekly self-swabs were processed by the DHSC, of which 126 324 were matched to study participants. Similar results have been seen for other vaccines where a reduced number or type of priming dose in infancy can lead to higher responses to a booster vaccine. Thelancet.com Vol 397 January 9, 2021 \fArticles Other coronavirus vaccine developers have released preliminary high-level results in public statements, including more than 90% efficacy reported for the lipid nanoparticle mRNA vaccine BNT162b2,11 92% efficacy for the Sputnik V vaccine,12 and 94·5% for the Moderna lipid nanoparticle mRNA-1273 vaccine.\n"
     ]
    }
   ],
   "source": [
    "key = \"1D69298B9E\"\n",
    "endpoint = 'https://api.smmry.com/'\n",
    "\n",
    "data = {\n",
    "    \"sm_api_input\":text\n",
    "}\n",
    "params = {\n",
    "    \"SM_API_KEY\": key,\n",
    "    \"SM_LENGTH\": \"7\"\n",
    "}\n",
    "headers = {\"Expect\":\"100-continue\"}\n",
    "response = requests.post(url=endpoint, params=params, data=data, headers=headers)\n",
    "\n",
    "summary = response.json()['sm_api_content']\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "source": [
    "Our second step of analysis is to extract the key ideas of the article in the form of keywords by using the YAKE module we have previously imported."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['vaccine efficacy', 'vaccine', 'efficacy', 'dose']\n"
     ]
    }
   ],
   "source": [
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_thresold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "windowSize = 1\n",
    "numOfKeywords = 4\n",
    "\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_thresold,\n",
    "                                            dedupFunc=deduplication_algo, windowsSize=windowSize, top=numOfKeywords, features=None)\n",
    "\n",
    "keywords = [word for word, score in custom_kw_extractor.extract_keywords(text)]\n",
    "\n",
    "print(keywords)"
   ]
  },
  {
   "source": [
    "Our next step is to associate each of these key phrases (also known as ngrams) with an image obtained from the google custom search API"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"AIzaSyDfAQR2Q3KIOjJUT-0_kJgmTCcB2_lcQPY\"\n",
    "search_engine_id = \"f980e922532fe1c1a\"\n",
    "\n",
    "for k in keywords:\n",
    "    payload = {'key': key, 'cx': search_engine_id, 'q': k, 'searchType': \"image\"}\n",
    "    query = 'https://www.googleapis.com/customsearch/v1?'\n",
    "    response = requests.get(query, params=payload)\n",
    "\n",
    "    i = 0\n",
    "    uri = \"\"\n",
    "\n",
    "    if 'error' in response.json().keys():\n",
    "        print(\"Google API Quota for today exceeded. Please obtain new keys or try again tomorrow\")\n",
    "    else:\n",
    "        while(not(uri.endswith(\".jpg\"))):\n",
    "            uri = response.json()['items'][i]['link']\n",
    "            i += 1\n",
    "\n",
    "        img_PIL = Image.open(requests.get(uri, stream=True).raw)\n",
    "        img_PIL.save(\"images/\"+k+\".jpg\")\n",
    "        img_PIL.show()"
   ]
  },
  {
   "source": [
    "Finally, we identify where the keywords and their corresponding ideas appear in the tex "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"vaccine efficacy\" is mentioned around line 37\n\"vaccine\" is mentioned around line 2262\n\"efficacy\" is mentioned around line 37\n\"dose\" is mentioned around line 27\n"
     ]
    }
   ],
   "source": [
    "def find_most_frequent_word(data, window_size, keyword):\n",
    "    most_frequent_window = -3\n",
    "    count_max = 0\n",
    "    for i in range(0, len(data), window_size):\n",
    "        curr_count = 0\n",
    "        for j in range(i, min(i+window_size, len(data))):\n",
    "            curr_count += data[j].count(keyword)\n",
    "            # do all the counting here\n",
    "        if count_max < curr_count:\n",
    "            count_max = curr_count\n",
    "            most_frequent_window = i+2\n",
    "            \n",
    "    return most_frequent_window\n",
    "\n",
    "data = text.splitlines()\n",
    "window_size = 5\n",
    "\n",
    "for k in keywords:\n",
    "    print(\"\\\"\" + k + \"\\\" is mentioned around line \", end=\"\")\n",
    "    print(find_most_frequent_word(data, window_size, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "source": [
    "***Citations*** \n",
    "\n",
    "**In-depth journal paper at Information Sciences Journal**\n",
    "\n",
    "Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289. pdf\n",
    "\n",
    "**ECIR'18 Best Short Paper**\n",
    "\n",
    "Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). A Text Feature Based Automatic Keyword Extraction Method for Single Documents. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 684 - 691. pdf\n",
    "\n",
    "Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). YAKE! Collection-independent Automatic Keyword Extractor. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 806 - 810. pdf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}