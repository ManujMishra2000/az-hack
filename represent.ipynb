{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "We start by importing \"Yet Another Keyword Extractor (Yake)\" - an open source unsupervised automatic Keyword extraction program."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "source": [
    "Next, we read in an input file with a large quantity of text to be analysed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data.txt\"\n",
    "\n",
    "f = open(filename, mode='r')\n",
    "text = f.read()"
   ]
  },
  {
   "source": [
    "Our first step of analysis is to summarise the text using the open source summary engine, SMMRY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"1D69298B9E\"\n",
    "endpoint = 'https://api.smmry.com/'\n",
    "\n",
    "data = {\n",
    "    \"sm_api_input\":text\n",
    "}\n",
    "params = {\n",
    "    \"SM_API_KEY\": key,\n",
    "    \"SM_LENGTH\": \"7\"\n",
    "}\n",
    "headers = {\"Expect\":\"100-continue\"}\n",
    "response = requests.post(url=endpoint, params=params, data=data, headers=headers)\n",
    "\n",
    "summary = response.json()['sm_api_content']\n",
    "print(summary)"
   ]
  },
  {
   "source": [
    "Our second step of analysis is to extract the key ideas of the article in the form of keywords by using the YAKE module we have previously imported."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_thresold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "windowSize = 1\n",
    "numOfKeywords = 4\n",
    "\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_thresold,\n",
    "                                            dedupFunc=deduplication_algo, windowsSize=windowSize, top=numOfKeywords, features=None)\n",
    "\n",
    "keywords = [word for word, score in custom_kw_extractor.extract_keywords(text)]\n",
    "print(keywords)"
   ]
  },
  {
   "source": [
    "Our next step is to associate each of these key phrases (also known as ngrams) with an image obtained from the google custom search API"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"AIzaSyBKbf_aR_m4i552iOuPAPb-VOJJkLn74yo\"\n",
    "search_engine_id = \"f980e922532fe1c1a\"\n",
    "\n",
    "for k in keywords:\n",
    "    payload = {'key': key, 'cx': search_engine_id, 'q': keyword, 'searchType': \"image\"}\n",
    "    query = 'https://www.googleapis.com/customsearch/v1?'\n",
    "    response = requests.get(query, params=payload)\n",
    "\n",
    "    i = 0\n",
    "    uri = \"\"\n",
    "    while(not(uri.endswith(\".jpg\"))):\n",
    "        uri = response.json()['items'][i]['link']\n",
    "        i += 1\n",
    "\n",
    "    img_PIL = Image.open(requests.get(uri, stream=True).raw)\n",
    "    img_PIL.save(\"output/images/\"+k+\".jpg\")\n",
    "    img_PIL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "source": [
    "***Citations*** \n",
    "\n",
    "**In-depth journal paper at Information Sciences Journal**\n",
    "\n",
    "Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289. pdf\n",
    "\n",
    "**ECIR'18 Best Short Paper**\n",
    "\n",
    "Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). A Text Feature Based Automatic Keyword Extraction Method for Single Documents. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 684 - 691. pdf\n",
    "\n",
    "Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). YAKE! Collection-independent Automatic Keyword Extractor. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 806 - 810. pdf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}